{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1yhndA8PCRxxH6RT0nMR60rDLbETs-vWn",
      "authorship_tag": "ABX9TyNalHd38ICVgmdynXC/fs5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/therishabhmittal-05/NLP/blob/main/CharacterRNN_LanguagePredict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-N2k1nFpHZ9w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import unicodedata\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import glob\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3mGjTINLuHO",
        "outputId": "66d82cdc-1b31-464c-8aec-cb26bc70b1d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allowed_chars = string.ascii_letters + \" .,;'\"+ \"_\"\n",
        "n_letters = len(allowed_chars)\n",
        "\n",
        "def unicode_ascii(s):\n",
        "  return \"\".join(\n",
        "      c for c in unicodedata.normalize(\"NFD\", s)\n",
        "      if unicodedata.category(c) != 'Mn'\n",
        "      and c in allowed_chars\n",
        "  )"
      ],
      "metadata": {
        "id": "X54vCHgAHnWF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(unicode_ascii('Ślusàrski'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRLyL_ZYJDTP",
        "outputId": "876be8dc-f54f-4d3e-fc4c-2ec13de8d01d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slusarski\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Letter to index\n",
        "def letter_index(letter):\n",
        "  if letter not in allowed_chars:\n",
        "    return allowed_chars.find('_')\n",
        "  else:\n",
        "     return allowed_chars.find(letter)\n",
        "\n",
        "# Sentence to tensor\n",
        "def sent_tensor(sent):\n",
        "  tensor = torch.zeros(len(sent), 1, n_letters)\n",
        "  for li, letter in enumerate(sent):\n",
        "    tensor[li][0][letter_index(letter)] = 1\n",
        "  return tensor"
      ],
      "metadata": {
        "id": "Mal5OIc1Jj5S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tensor('Rishabh Mittal')\n",
        "sent_tensor('$')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__HgLHDkKtR9",
        "outputId": "2316bd13-ebff-43d7-c772-e0b736a7dee7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LangDs(Dataset):\n",
        "\n",
        "  def __init__(self, data_dir):\n",
        "    self.data_dir = data_dir\n",
        "    labels_set = set()\n",
        "\n",
        "    self.data = []\n",
        "    self.data_tensors = []\n",
        "    self.labels = []\n",
        "    self.label_tensors=[]\n",
        "\n",
        "    text_files = glob.glob(os.path.join(data_dir, '*txt'))\n",
        "    for filename in text_files:\n",
        "      label = os.path.splitext(os.path.basename(filename))[0]\n",
        "      labels_set.add(label)\n",
        "      lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "      for name in lines:\n",
        "        self.data.append(name)\n",
        "        self.data_tensors.append(sent_tensor(name))\n",
        "        self.labels.append(label)\n",
        "\n",
        "      self.labels_uniq = list(labels_set)\n",
        "      for idx in range(len(self.labels)):\n",
        "        temp_tensor = torch.tensor([self.labels_uniq.index(self.labels[idx])], dtype=torch.long)\n",
        "        self.label_tensors.append(temp_tensor)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data_item = self.data[idx]\n",
        "    data_label = self.labels[idx]\n",
        "    data_tensor = self.data_tensors[idx]\n",
        "    label_tensor = self.label_tensors[idx]\n",
        "\n",
        "    return data_item, data_label, data_tensor, label_tensor"
      ],
      "metadata": {
        "id": "UCnXShkSKvXV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alldata = LangDs('/content/drive/MyDrive/Colab Notebooks/data/data/names')"
      ],
      "metadata": {
        "id": "Ax2_oqykNAqr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, val_set = random_split(alldata, [(int)(len(alldata)*0.85), len(alldata) - (int)(len(alldata)*0.85)], generator=torch.Generator().manual_seed(42))"
      ],
      "metadata": {
        "id": "WDkfP-78P7Ej"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdGQcXff5WnD",
        "outputId": "2f82fbf5-5bd7-4a67-afb4-73c459257ba3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = list(range(len(train_set)))\n",
        "print(len(indices))\n",
        "random.shuffle(indices)\n",
        "batches = np.array_split(indices, len(indices) // 64)\n",
        "print(len(batches[37]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jDLxGQxTOhW",
        "outputId": "285c2b10-8bc7-483a-e1a1-c52ffc7db149"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17062\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LangModel(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(LangModel, self).__init__()\n",
        "\n",
        "    self.rnn = nn.RNN(input_size, hidden_size)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, senttensor):\n",
        "    rnn_out, ahat = self.rnn(senttensor)\n",
        "    ahat = self.fc(ahat[0])\n",
        "    yhat = self.softmax(ahat)\n",
        "    return yhat\n"
      ],
      "metadata": {
        "id": "V2S_K0ToqEZY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 128\n",
        "model = LangModel(n_letters, n_hidden, len(alldata.labels_uniq)).to(device)\n",
        "print(\"Device: cuda\" if next(model.parameters()).is_cuda else \"Device: cpu\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbH0Htx4sMUw",
        "outputId": "9627f1d8-4097-4c14-8bcc-0db98cba2fa7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device : cuda\n",
            "LangModel(\n",
            "  (rnn): RNN(58, 128)\n",
            "  (fc): Linear(in_features=128, out_features=18, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = sent_tensor('Alexandra').to(device)\n",
        "output = model(input)\n",
        "def get_label_from_output(output, output_labels):\n",
        "  _, top_i = output.topk(1)\n",
        "  label_i = top_i[0].item()\n",
        "  return output_labels[label_i], label_i\n",
        "print(get_label_from_output(output, alldata.labels_uniq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOG4iUCLsZOA",
        "outputId": "eb6c5cc7-5f0f-4050-cb55-2f9a9839ee4d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Polish', 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, n_epochs=10, batch_size=64, report=50, lr = 0.2, criterion = nn.NLLLoss()):\n",
        "  losses=[] # to store loss after each epoch for plotting\n",
        "  model.train() # train mode\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  print(f\"length of train data: {len(train_data)}\")\n",
        "  for iter in range(1, n_epochs+1):\n",
        "    running_loss = 0.0 # One epoch loss\n",
        "\n",
        "    # create some minibatches\n",
        "    # we cannot use dataloaders because each of our names is a different length\n",
        "    indices = list(range(len(train_data)))\n",
        "    random.shuffle(indices)\n",
        "    batches = np.array_split(indices, max(1, len(indices) // batch_size))\n",
        "\n",
        "    for idx, batch in enumerate(batches):\n",
        "      batch_loss = 0.0 # per batch loss, added to running loss after each batch run\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # For each word in the batch\n",
        "      for i in batch:\n",
        "        (data_item, data_label, data_tensor, label_tensor) = train_data[i]\n",
        "        data_tensor = data_tensor.to(device)\n",
        "        label_tensor = label_tensor.to(device)\n",
        "        output = model(data_tensor)\n",
        "        loss = criterion(output, label_tensor)\n",
        "        batch_loss += loss\n",
        "      batch_loss /= len(batch)\n",
        "      batch_loss.backward()\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), max_norm=3)\n",
        "      optimizer.step()\n",
        "      running_loss += batch_loss.item()\n",
        "\n",
        "    losses.append(running_loss/len(batches))\n",
        "    if(iter%report==0):\n",
        "      print(f\"Epoch: {iter} | Epoch Loss: {losses[-1]} \")\n",
        "    running_loss = 0 # set to zero again, to calculate loss for next epoch\n",
        "  return losses # list of losses at each epoch"
      ],
      "metadata": {
        "id": "nfbfQ3yL0Znw"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "losses = train(model, train_set, n_epochs=30, report=5)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"training took {end-start}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjCfLylQ08Su",
        "outputId": "80db1261-3208-4e38-c00d-c742d8f119e5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of train data: 17062\n",
            "Epoch: 5 | Epoch Loss: 0.7993450484105519 \n",
            "Epoch: 10 | Epoch Loss: 0.7255371973702782 \n",
            "Epoch: 15 | Epoch Loss: 0.6636278130730292 \n",
            "Epoch: 20 | Epoch Loss: 0.6248615726940614 \n",
            "Epoch: 25 | Epoch Loss: 0.57053168308466 \n",
            "Epoch: 30 | Epoch Loss: 0.5407787313810865 \n",
            "training took 519.369300365448s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = sent_tensor('Jing').to(device)\n",
        "output = model(input)\n",
        "def get_label_from_output(output, output_labels):\n",
        "  _, top_i = output.topk(1)\n",
        "  label_i = top_i[0].item()\n",
        "  return output_labels[label_i], label_i\n",
        "print(get_label_from_output(output, alldata.labels_uniq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gFIQ-z17_DA",
        "outputId": "c0027388-5c88-453e-be0d-74566c05c18e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('German', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval()"
      ],
      "metadata": {
        "id": "Gva86MLuWQ-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}